{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "#определяю регион страны\n",
    "from countryinfo import CountryInfo #https://github.com/porimol/countryinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Гипотеза:  \n",
    "___Экономика государств с развитой государственной поддержкой инновационных предприятий (инновационной системы) растёт интенсивнее.___\n",
    "\n",
    "Для этого, выбираю следующие показатели:  \n",
    "\n",
    "___1.1.\tPolitical environment (интегральный покозатель)___  \n",
    "1.1.1.\tPolitical stability and absence of violence/terrorism  \n",
    "1.1.2.\tGovernment effectiveness  \n",
    "1.1.3.\tPress freedom  \n",
    "\n",
    "___1.2.\tRegulatory environment (интегральный покозатель)___  \n",
    "1.2.1.\tRegulatory quality  \n",
    "1.2.2.\tRule of law  \n",
    "1.2.3.\tCost of redundancy dismissal  \n",
    "\n",
    "___1.3.\tBusiness environment (интегральный покозатель)___  \n",
    "1.3.1.\tEase of starting a business  \n",
    "1.3.2.\tEase of resolving insolvency  \n",
    "1.3.3.\tEase of paying taxes  \n",
    "\n",
    "2.1.1.\tExpenditure on education  \n",
    "2.1.2.\tPublic expenditure on education per pupil  \n",
    "\n",
    "2.1.5.\tPupil-teacher ratio, secondary  \n",
    "\n",
    "2.2.1.\tTertiary enrolment  \n",
    "2.2.2.\tGraduates in science and engineering  \n",
    "\n",
    "2.3.1.\tResearchers  \n",
    "2.3.2.\tGross expenditure on R&D (GERD)  \n",
    "\n",
    "3.1.3.\tGovernment's online service  \n",
    "\n",
    "3.2.1.\tElectricity output  \n",
    "3.2.3.\tLogistics performance  \n",
    "\n",
    "3.3.2.\tEnvironmental performance  \n",
    "\n",
    "\n",
    "___4.1.\tCredit (интегральный покозатель)___  \n",
    "4.1.1.\tEase of getting credit  \n",
    "4.1.2.\tDomestic credit to private sector  \n",
    "4.1.3.\tMicrofinance institutions' gross loan portfolio  \n",
    "\n",
    "4.2.1.\tEase of protecting investors  \n",
    "\n",
    "4.2.4.\tVenture capital deals  \n",
    "\n",
    "4.3.2.\tMarket access for non-agricultural exports  \n",
    "4.3.3.\tIntensity of local competition  \n",
    "\n",
    "5.1.2.\tFirms offering formal training  \n",
    "\n",
    "___5.2.\tInnovation linkages (интегральный покозатель)___   \n",
    "5.2.1.\tUniversity/industry research collaboration  \n",
    "5.2.2.\tState of cluster development  \n",
    "5.2.3.\tGERD financed by abroad  \n",
    "5.2.4.\tJoint venture/strategic alliance deals  \n",
    "5.2.5.\tPatent families filed in at least three offices  \n",
    "\n",
    "5.3.1.\tRoyalties and license fees payments (% of service imports)  \n",
    "5.3.4.\tForeign direct investment net inflows  \n",
    "\n",
    "6.1.2.\tPatent Cooperation Treaty resident applications  \n",
    "\n",
    "6.3.4.\tForeign direct investment net outflows\n",
    "\n",
    "Я выбрал 37 показателей, которые могут характеризовать государственную поддержку и 5 интегральных позателей (вероятно они могут быть полезны для свёртки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fe = ['Political stability and absence of violence/terrorism',\n",
    "           'Government effectiveness',\n",
    "           'Press freedom','Regulatory quality',\n",
    "           'Rule of law', 'Cost of redundancy dismissal',\n",
    "           'Ease of starting a business',\n",
    "           'Ease of resolving insolvency',\n",
    "           'Ease of paying taxes',\n",
    "           'Expenditure on education',\n",
    "           'Public expenditure on education per pupil',\n",
    "           'Pupil-teacher ratio, secondary',\n",
    "           'Tertiary enrolment',\n",
    "           'Graduates in science and engineering','Researchers',\n",
    "           'Gross expenditure on R&D (GERD)',\n",
    "           \"Government's online service\",\n",
    "           'Electricity output',\n",
    "           'Logistics performance',\n",
    "           'Environmental performance',\n",
    "           'Ease of getting credit',\n",
    "           'Domestic credit to private sector',\n",
    "           \"Microfinance institutions' gross loan portfolio\",\n",
    "           'Ease of protecting investors',\n",
    "           'Venture capital deals',\n",
    "           'Market access for non-agricultural exports',\n",
    "           'Intensity of local competition',\n",
    "           'Firms offering formal training',\n",
    "           'University/industry research collaboration',\n",
    "           'State of cluster development',\n",
    "           'GERD financed by abroad',\n",
    "           'Joint venture/strategic alliance deals',\n",
    "           'Patent families filed in at least three offices',\n",
    "           'Royalties and license fees payments (% of service imports)',\n",
    "           'Foreign direct investment net inflows',\n",
    "           'Patent Cooperation Treaty resident applications',\n",
    "           'Foreign direct investment net outflows']\n",
    "#интегральные показатели\n",
    "list_intfe = ['Political environment', 'Regulatory environment', 'Business environment', 'Credit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:\\\\Users\\\\dserp\\\\ML\\\\Degree_ML\\\\full'\n",
    "file_list = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирую датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {} #словарь датасетов с показателми без интегральных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переименоваю названия стран, для дальнейшего распознования региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'Bolivia (Plurinational State of)' : 'Bolivia',\n",
    "    'Bolivia, Plurinational St.' : 'Bolivia',\n",
    "    'Bolivia, Plurinational State of' : 'Bolivia',\n",
    "    'Bahamas' : 'Commonwealth of The Bahamas',\n",
    "    'Bahamas, Commonwealth of the' : 'Commonwealth of The Bahamas',\n",
    "    'Bahamas, Commonwealth of' : 'Commonwealth of The Bahamas',\n",
    "    'Brunei Darussalam' : 'Nation of Brunei',\n",
    "    'Brunei' : 'Nation of Brunei',\n",
    "    'Cabo Verde' : 'Cape Verde',\n",
    "    'Congo, Democratic Republic of the': 'Republic of the Congo',\n",
    "    'Congo' : 'Republic of the Congo',\n",
    "    \"Cote d'Ivoire\" : 'Ivory Coast',\n",
    "    \"Côte d'Ivoire\" : 'Ivory Coast',\n",
    "    'Cote dIvoire' : 'Ivory Coast',\n",
    "    'Czech Republic (the)' : 'Czech Republic',\n",
    "    'Dominican Republic (the)' : 'Dominican Republic',\n",
    "    'Iran (Islamic Republic of)' : 'Iran',\n",
    "    'Iran, Islamic Rep.' : 'Iran',\n",
    "    'Iran, Islamic Republic of' : 'Iran',\n",
    "    'Gambia' : 'Republic of The Gambia',\n",
    "    'Guinea-Bissau' : 'Republic of Guinea-Bissau',\n",
    "    'Guinea Bissau' : 'Republic of Guinea-Bissau',\n",
    "    'Guinea-Bissau, Republic of': 'Republic of Guinea-Bissau',\n",
    "    'Holy See (Vatican City State)' : 'Vatican',\n",
    "    'Hong Kong (China)' : 'Hong Kong',\n",
    "    'Hong Kong, China' : 'Hong Kong',\n",
    "    \"Korea, Democratic People's Republic of\" : \"Democratic People's Republic of Korea\",\n",
    "    'Korea, Rep.' : 'Republic of Korea',\n",
    "    'Republic of Korea (the)' : 'Republic of Korea',\n",
    "    'Korea, Republic of' : 'Republic of Korea',\n",
    "    'Moldova, Rep.' : 'Moldova',\n",
    "    'Moldova, Republic of' : 'Moldova',\n",
    "    'Micronesia, Federated States of' : 'Federated States of Micronesia',\n",
    "    'Micronesia' : 'Federated States of Micronesia',\n",
    "    'Republic of Moldova (the)' : 'Moldova',\n",
    "    'North Macedonia' : 'Republic of Macedonia',\n",
    "    'TFYR Macedonia' : 'Republic of Macedonia',\n",
    "    'The Former Yugoslav Republic (FYR) of Macedonia' : 'Republic of Macedonia',\n",
    "    'Timor-Leste' : 'Democratic Republic of Timor-Leste',\n",
    "    'Netherlands (the)' : 'Netherlands',\n",
    "    'Niger (the)' : 'Niger',\n",
    "    'Russian Federation (the)' : 'Russian Federation',\n",
    "    'Sudan (pre-secession)' : 'Sudan',\n",
    "    'Sao Tome and Principe' : \"Democratic Republic of São Tomé and Príncipe\",\n",
    "    'Tanzania, United Rep.' : 'Tanzania',\n",
    "    'Tanzania, United Republic of' : 'Tanzania',\n",
    "    'United Republic of Tanzania (the)' : 'Tanzania',\n",
    "    'Taiwan, Province of China' : 'Taiwan',\n",
    "    'United Arab Emirates (the)' : 'United States of America',\n",
    "    'United States of America (the)' : 'United States of America',\n",
    "    'United Kingdom (the)' : 'United Kingdom',\n",
    "    'Venezuela, Bolivarian Rep.' : 'Venezuela',\n",
    "    'Venezuela, Bolivarian Republic of' : 'Venezuela',\n",
    "    'Viet Nam' : 'VietNam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    df_temp = pd.read_csv(os.path.join(data_dir, file))\n",
    "        \n",
    "    #Переименовываю столбцы \n",
    "    df_temp.rename(columns = {list(df_temp.iloc[:, [0]])[0] : re.sub('\\D','', file), \n",
    "                            list(df_temp.iloc[:, [1]])[0] : 'Indicator'},\n",
    "                   inplace = True)\n",
    "                   \n",
    "    #переименование стран\n",
    "    df_temp.rename(columns = rename_dict, inplace = True)\n",
    "    \n",
    "    #удаляю дупликаты\n",
    "    df_temp = df_temp.loc[:,~df_temp.columns.duplicated()]\n",
    "    \n",
    "    #удаляю строку 'Indicator' (индекс 0) и 'Index' (индекс 4 или 5) - они содержат только Nan (видимо для красоты таблички, для открытия в Excel)\n",
    "    a = df_temp.loc[df_temp[list(df_temp.iloc[:, [0]])[0]] == 'Index'].index\n",
    "    df_temp.drop([0, a[0]], inplace = True)\n",
    "\n",
    "    #в датафрейме есть значения '  '(и не числовые значения) - несколько пробелов, заменяю их на None\n",
    "    df_temp.iloc[:,3:] = df_temp.iloc[:,3:].replace(to_replace = '[\\D]', value = np.nan, regex = True)\n",
    "    \n",
    "    #заполняю пропуски нулями\n",
    "    df_temp.fillna(0, inplace = True)\n",
    "    \n",
    "    #отсекаю всё лишнее\n",
    "    df_temp = df_temp.loc[:, :'Zimbabwe']\n",
    "                \n",
    "    indicators_temp = pd.DataFrame(data = None, columns = list(df_temp))\n",
    "    for i in list_fe:\n",
    "        indicators_temp = pd.concat([indicators_temp, df_temp.loc[df_temp['Indicator']== i]])\n",
    "    indicators_temp.drop(list(df_temp.iloc[:, [2]])[0], axis = 1, inplace = True)\n",
    "    \n",
    "    #добавляю показатели в датасет\n",
    "    data[re.sub('\\D','', file)] = indicators_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кличество стран 2013 : 149\n",
      "Кличество стран 2014 : 229\n",
      "Кличество стран 2015 : 229\n",
      "Кличество стран 2016 : 229\n",
      "Кличество стран 2017 : 127\n",
      "Кличество стран 2018 : 126\n",
      "Кличество стран 2019 : 128\n"
     ]
    }
   ],
   "source": [
    "count_country = {}\n",
    "for i in data.keys():\n",
    "    count_country[i] = len(list(data[i])) -2\n",
    "    print('Кличество стран', i, ':', len(list(data[i])) -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2014': 229}\n"
     ]
    }
   ],
   "source": [
    "max_country = {}\n",
    "for key in data.keys():\n",
    "    if count_country[key] == max(count_country.values()):\n",
    "        max_country[key] = max(count_country.values())\n",
    "        break\n",
    "print(max_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andorra\n",
      "Channel Islands\n",
      "Curaçao\n",
      "Vatican\n",
      "Kosovo\n",
      "Macao\n",
      "Montenegro\n",
      "Myanmar\n",
      "Netherlands Antilles\n",
      "Palestinian Territory, Occupied\n",
      "Saint Martin (French part)\n",
      "Sint Maarten (Dutch part)\n",
      "Turks and Caicos Islands\n",
      "Virgin Islands, British\n",
      "Virgin Islands, U.S.\n",
      "Количество нераспознанных стран: 15\n"
     ]
    }
   ],
   "source": [
    "err_country = []\n",
    "region = pd.DataFrame({'country': list(data[list(max_country.keys())[0]])[3:], 'region': None})\n",
    "for i in range(len(region.country)):\n",
    "    try:\n",
    "        region.region[i] = CountryInfo(region.country[i]).subregion()\n",
    "    except:\n",
    "        err_country.append(region.country[i])\n",
    "region.drop_duplicates(inplace = True)\n",
    "\n",
    "for i in err_country:\n",
    "    print(i)\n",
    "print('Количество нераспознанных стран:', len(err_country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполняю в ручную\n",
    "region.loc[region.country == err_country[0],['region']] = 'Western Europe' #Andorra\n",
    "region.loc[region.country == err_country[1],['region']] = 'Western Europe' #Channel Islands\n",
    "region.loc[region.country == err_country[2],['region']] = 'Caribbean' #Curaçao\n",
    "region.loc[region.country == err_country[3],['region']] = 'Southern Europe' #Holy See (Vatican City State)\n",
    "region.loc[region.country == err_country[4],['region']] = 'Eastern Europe' #Kosovo (used: Republic of Serbia)\n",
    "region.loc[region.country == err_country[5],['region']] = 'Eastern Asia' #Macao (used: China)\n",
    "region.loc[region.country == err_country[6],['region']] = 'Southern Europe' #Montenegro (used: Bosnia-Herzegovina)\n",
    "region.loc[region.country == err_country[7],['region']] = 'Southern Asia' #Myanmar (used: Bangladesh)\n",
    "region.loc[region.country == err_country[8],['region']] = 'South America' #Netherlands Antilles (used: Venezuela)\n",
    "region.loc[region.country == err_country[9],['region']] = 'Western Asia' #Palestinian Territory, Occupied (used: Israel)\n",
    "region.loc[region.country == err_country[10],['region']] = 'Caribbean' #Saint Martin (French part)\n",
    "region.loc[region.country == err_country[11],['region']] = 'Caribbean' #Sint Maarten (Dutch part)\n",
    "region.loc[region.country == err_country[12],['region']] = 'South America' #Turks and Caicos Islands (used: Cuba)\n",
    "region.loc[region.country == err_country[13],['region']] = 'Caribbean' #Virgin Islands, British\n",
    "region.loc[region.country == err_country[14],['region']] = 'Caribbean' #Virgin Islands, U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['region'] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gii = pd.DataFrame(data = None, columns = list(region['country']))\n",
    "\n",
    "for file in file_list:\n",
    "    gii_temp = pd.read_csv(os.path.join(data_dir, file))    \n",
    "    gii_temp = gii_temp.loc[:1, 'Albania':'Zimbabwe']    \n",
    "    gii_temp.drop([0], inplace = True)    \n",
    "    gii_temp.rename(columns = rename_dict, inplace = True)    \n",
    "    gii_temp = gii_temp.loc[:,~gii_temp.columns.duplicated()]    \n",
    "    gii_temp.index.values[0] = re.sub('\\D','',file)    \n",
    "    gii = pd.concat([gii, gii_temp], sort=False)\n",
    "    gii.fillna(gii.mean(), inplace = True)\n",
    "    gii.fillna(0, inplace = True)\n",
    "\n",
    "data['GII'] = gii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняю датасет в json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type DataFrame is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e38737bcc146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\dserp\\\\ML\\\\Degree_ML\\\\dataset_GW.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type DataFrame is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open(\"C:\\\\Users\\\\dserp\\\\ML\\\\Degree_ML\\\\dataset_GW.json\", \"w\") as wf:\n",
    "    json.dump(data, wf, indent = 4)\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7d87dd16c8ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\dserp\\\\ML\\\\Degree_ML\\\\dataset_GW.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    409\u001b[0m             )\n\u001b[0;32m    410\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         ]\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program_Files\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(data).to_csv(\"C:\\\\Users\\\\dserp\\\\ML\\\\Degree_ML\\\\dataset_GW.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
